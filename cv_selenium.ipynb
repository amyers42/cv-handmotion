{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45af78c4-e8c2-4b3a-ba2f-401c2235af16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Search box ready\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Live ASL → Google Search via MediaPipe + ResNet-18 + Selenium\n",
    "Requirements:\n",
    "    pip install torch torchvision opencv-python pillow mediapipe selenium\n",
    "    Download ChromeDriver from https://chromedriver.chromium.org/downloads\n",
    "    and put it on your PATH so that `webdriver.Chrome()` works.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# ----------------------------\n",
    "# Selenium Configuration\n",
    "# ----------------------------\n",
    "URL          = \"https://www.google.com\"\n",
    "INPUT_NAME   = \"q\"          # name attribute for Google search box\n",
    "WAIT_TIMEOUT = 30\n",
    "\n",
    "# ----------------------------\n",
    "# ASL Model Configuration\n",
    "# ----------------------------\n",
    "CKPT_PATH           = r\"best_asl_resnet_checkpoint_5.pth\"\n",
    "DEVICE              = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "STABILITY_THRESHOLD = 15\n",
    "INPUT_SIZE          = (224, 224)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Initialize Selenium WebDriver & accept consent if needed\n",
    "# ----------------------------\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(URL)\n",
    "\n",
    "# 1a) Accept Google's consent dialog if presented\n",
    "try:\n",
    "    consent_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((\n",
    "            By.XPATH,\n",
    "            \"//button[.//div[contains(text(),'I agree') or contains(text(),'Accept all')]]\"\n",
    "        ))\n",
    "    )\n",
    "    consent_btn.click()\n",
    "    print(\"✅ Consent dialog accepted\")\n",
    "except TimeoutException:\n",
    "    pass  # no consent dialog\n",
    "\n",
    "# 1b) Wait for the search box to appear\n",
    "try:\n",
    "    input_el = WebDriverWait(driver, WAIT_TIMEOUT).until(\n",
    "        EC.visibility_of_element_located((By.NAME, INPUT_NAME))\n",
    "    )\n",
    "    input_el.click()\n",
    "    print(\"✅ Search box ready\")\n",
    "except TimeoutException:\n",
    "    print(\"❌ Could not find the search box. Dumping page source for debug:\")\n",
    "    print(driver.page_source)\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Load ASL model\n",
    "# ----------------------------\n",
    "class_names = [chr(ord('A') + i) for i in range(26)] + ['Blank']\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ckpt = torch.load(r\"best_asl_resnet_checkpoint_5.pth\", map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.to(device).eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Preprocessing & keymap\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "keymap = {c: c.lower() for c in class_names if c != 'Blank'}\n",
    "keymap['Blank'] = None\n",
    "\n",
    "# ----------------------------\n",
    "# 4) MediaPipe Hands setup\n",
    "# ----------------------------\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Live loop: capture, predict, send_keys\n",
    "# ----------------------------\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Could not open camera. Check index or permissions.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "time.sleep(1.0)  # camera warm-up\n",
    "\n",
    "last_letter = None\n",
    "count = 0\n",
    "buffer_text = \"\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"⚠️ Frame capture failed, exiting.\")\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        lm = results.multi_hand_landmarks[0].landmark\n",
    "        xs = [p.x for p in lm]\n",
    "        ys = [p.y for p in lm]\n",
    "        xmin, xmax = int(min(xs) * w), int(max(xs) * w)\n",
    "        ymin, ymax = int(min(ys) * h), int(max(ys) * h)\n",
    "        margin = 20\n",
    "        xmin, ymin = max(0, xmin - margin), max(0, ymin - margin)\n",
    "        xmax, ymax = min(w, xmax + margin), min(h, ymax + margin)\n",
    "\n",
    "        crop = frame[ymin:ymax, xmin:xmax]\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        inp = transform(pil_img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(inp)\n",
    "            _, pred = out.max(1)\n",
    "            letter = class_names[pred.item()]\n",
    "\n",
    "        # debounce logic\n",
    "        if letter == last_letter:\n",
    "            count += 1\n",
    "        else:\n",
    "            last_letter = letter\n",
    "            count = 1\n",
    "\n",
    "        if count == STABILITY_THRESHOLD:\n",
    "            key = keymap[letter]\n",
    "            if key:\n",
    "                input_el.send_keys(key)\n",
    "                buffer_text += letter\n",
    "            count = 0\n",
    "\n",
    "        # draw annotations\n",
    "        mp_drawing.draw_landmarks(frame, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS)\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, letter, (xmin, ymin - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "    # overlay typed buffer\n",
    "    cv2.putText(frame, buffer_text, (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('ASL → Google Search', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3215b26-597f-41ec-96cc-cfcf735f292e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv2025)",
   "language": "python",
   "name": "cv2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
